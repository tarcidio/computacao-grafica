{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código 15: Iluminação\n",
    "\n",
    "\n",
    "PS TEM QUE CORRIGIR OS COMENTÁRIOS DA MALHA NO LOAD FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Código pré loop principal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialização do glfw e criação da janela\n",
    "\n",
    "**Conceitos iniciais**\n",
    "\n",
    "* Fonte de luz: qualquer objeto que emite energia brilhante\n",
    "* Luz branca é a combinação das cores do espectro\n",
    "* Toda superfície absorve algumas cores e reflete outras cores\n",
    "* A cor da superfície é a cor refletida (ou seja, não absorvida) e visível aos nossos olhos\n",
    "* Modelos de iluminação: representação matemática ou algorítmica que descreve como a luz interage com superfícies tridimensionais para criar uma imagem visual. Exemplo:\n",
    "    * Luz (branca) = RGB (1.0, 1.0, 1.0)\n",
    "    * Objeto = RGB (1.0, 0.5, 0.31)\n",
    "    * Objeto x Luz = RGB (1.0, 0.5, 0.31)\n",
    "* Fonte de luz pontual: fonte de luz que é considerada como uma fonte infinitesimalmente pequena e concentrada em um único ponto no espaço\n",
    "\n",
    "**Tipos de Iluminação**\n",
    "\n",
    "* **Luz Ambiente**: iluminação geral presente em um ambiente, resultante da luz, sem uma fonte específica, que é dispersa em várias direções após interagir com superfícies e objetos. É responsável por garantir que objetos e cenários sejam visíveis, mesmo em áreas não diretamente iluminadas por fontes de luz diretas\n",
    "* **Reflexão Difusa**: quando uma luz incide sobre uma superfície áspera ou irregular e é dispersa em muitas direções diferentes, produzindo iluminação suave e uniforme\n",
    "* **Reflexão Especular**: quando uma luz incide sobre uma superfície lisa e reflete em um ângulo específico, seguindo a lei da reflexão, resultando em reflexos brilhantes e intensos que reproduzem a imagem da fonte de luz. Superfícies altamente polidas, como espelhos ou metais brilhantes, são exemplos de materiais que exibem reflexão especular perfeita. Em contexto de Computação Gráfica, podemos definir melhor específicamente como reflexão da luz incidente em uma área concentrada ao redor de um ângulo.\n",
    "\n",
    "**Modelos e matemática**\n",
    "\n",
    "Para representar essas três maneiras de iluminação, criou-se modelos com base nas leis físicas que aproximam o cenário da realidade. Porém, estes modelos não são exatos e não tem objetivo de serem, uma vez que o custo para computar um modelo realista é extremamente alto.\n",
    "\n",
    "* **Luz Ambiente**: cada objeto irá refletir luz conforme ($i$) suas propriedades e a ($ii$) intensidade da luz\n",
    "\n",
    "    ($i$) $k_a$: coeficiente de reflexão ambiente do objeto, com $k_a \\in [0,1]$\n",
    "\n",
    "    ($ii$) $I_a$: intensidade da luz ambiente, com $I_a \\in [0,1]$\n",
    "    \n",
    "* **Reflexão Difusa**: quantidade de luz incidente depende do ângulo de incidência $\\theta$ entre a direção da luz incidente e a normal da superfıcie. Quanto menor, mais forte é a reflexão e vice versa. Essa fato explica a dependência da reflexão pelo $cos(\\theta)$. Considere:\n",
    "    * $\\overrightarrow{P_{source}}$: posição da fonte de luz\n",
    "    * $\\overrightarrow{P_{surf}}$: posição da surpefície\n",
    "    * $\\overrightarrow{L}$: vetor unitário que representa a direção da Luz. É dado por $$\\overrightarrow{L} = \\frac{\\overrightarrow{P_{source}} - \\overrightarrow{P_{surf}}}{|\\overrightarrow{P_{source}} - \\overrightarrow{P_{surf}}|}$$\n",
    "    \n",
    "    * $\\overrightarrow{N}$: vetor unitário normal à superfície. Um vértice sozinho não forma superfície, então $\\overrightarrow{N}$ pode ser calculado considerando a superfície local formada por vértices vizinhos. Em termos práticos, um objeto será importado em .obj e ele terá várias faces. O arquivo .obj indicará quais são as normais das faces desse objeto. Essas normais serão usadas para os cálculos. Vértices de uma mesma face usará a mesma normal, exceto se o arquivo .obj especificar algo diferente. Em geral, normais dos vértices das arestas também são especificados.\n",
    "    \n",
    "    ![Normal](15_Iluminacao02.png)\n",
    "    \n",
    "    * $cos(\\theta) = \\overrightarrow{N} \\cdot \\overrightarrow{L}$. Note que o objeto será iluminado apenas se $0.0 \\leq \\theta \\leq 90º$. Se $\\theta < 0.0$, luz estará atrás da superfície.\n",
    "\n",
    "    ![N, L e theta](15_Iluminacao01.png)\n",
    "    * Modelo final para reflexão difusa e ambiente: $$I_{diff} =\n",
    "\\begin{cases}\n",
    "k_aI_a + k_dI_l(\\overrightarrow{N}\\cdot\\overrightarrow{L}) & \\text{ se } \\overrightarrow{N}\\cdot\\overrightarrow{L} > 0 \\\\ \n",
    "k_aI_a  & \\text{ se } \\overrightarrow{N}\\cdot\\overrightarrow{L} \\leq 0\n",
    "\\end{cases}$$\n",
    "Onde,\n",
    "        * $k_a$: coeficiente de reflexão ambiente do objeto, com $k_a \\in [0,1]$\n",
    "        * $I_a$: intensidade da luz ambiente, com $I_a \\in [0,1]$\n",
    "        * $k_d$: coeficiente de reflexão difusa do objeto, com $k_d \\in [0,1]$\n",
    "        * $I_l$: intensidade da luz pontual, com $I_l \\in [0,1]$\n",
    "        * $\\overrightarrow{N}$: vetor unitário normal à superfície\n",
    "        * $\\overrightarrow{L}$: vetor unitário que representa a direção da Luz\n",
    "\n",
    "    ![k_a e k_d](15_Iluminacao03.png)\n",
    "\n",
    "* **Reflexão Especular**: essa reflexão depende do campo de reflexão especular. Para entender melhor esse efeito, definamos:\n",
    "    * $\\overrightarrow{R}$: vetor unitário que representa a direção da reflexão especular\n",
    "    * $\\overrightarrow{V}$: vetor unitário que representa a direção do observador\n",
    "    * $\\phi$: ângulo entre $\\overrightarrow{R}$ e $\\overrightarrow{V}$\n",
    "\n",
    "    ![R e V](15_Iluminacao04.png)\n",
    "\n",
    "    * **Campo de reflexão especular**: superfícies perfeitamente brilhantes refletem de forma organizada os raios de luz. Ou seja, um raio de luz que incide em uma superfície perfeitamente brilhante sempre vai refletir a partir de um ângulo $\\theta$ da normal. Porém, superfícies menos brilhante refletem com um ângulo aproximadamente $\\theta$, mas não $\\theta$ exatamente. O ângulo varia, mas a variação é pequena. Superfície foscas refletem de forma completamente desorganizada e esse ângulo costuma variar muito. Essa área que é definida por essa variação é chamada de campo de reflexão especular. Superfícies brilhantes tem um campo menor de reflexão especular, enquanto que superfícies foscas tem um campo maior de reflexão especular.\n",
    "\n",
    "    ![Campo de Reflexão Especular](15_Iluminacao05.png)\n",
    "\n",
    "    * **Modelo de Phong**: modelo que modela o campo de reflexão especular. Define que a intensidade de reflexão especular depende de $cos^{n_s}(\\phi)$, onde $n_s$ é expoente de reflexão especular. Quanto mais brilhante a superfície, mais $n_s \\rightarrow \\infty$. O modelo de matemático é definido como: $$I_{l,spec} =\n",
    "\\begin{cases}\n",
    "k_sI_l(\\overrightarrow{V}\\cdot\\overrightarrow{R})^{n_s} & \\text{ se } \\overrightarrow{V}\\cdot\\overrightarrow{R} > 0 \\\\ \n",
    "0.0 & \\text{ se } \\overrightarrow{V}\\cdot\\overrightarrow{R} \\leq 0\n",
    "\\end{cases}$$\n",
    "        Onde,\n",
    "        * $k_s$: coeficiente de reflexão especular, com $k_s \\in [0,1]$. Define o quão brilhante será a reflexão especular.\n",
    "        * $n_s$: expoente de reflexão especular. Define o campo de reflexão especular.\n",
    "        * $cos(\\phi) = \\overrightarrow{V}\\cdot\\overrightarrow{R}$\n",
    "\n",
    "        ![Efeito do modelo de Phong](15_Iluminacao08.png)\n",
    "\n",
    "        Porém, qual o valor de $\\overrightarrow{V}$ e de $\\overrightarrow{R}$?\n",
    "        * $\\overrightarrow{V} = \\frac{\\overrightarrow{P_{cam}} - \\overrightarrow{P_{surf}}}{|\\overrightarrow{P_{cam}} - \\overrightarrow{P_{surf}}|}$\n",
    "        * $|\\overrightarrow{R}| = |\\overrightarrow{N}|(2\\overrightarrow{N}\\cdot\\overrightarrow{L}) - |\\overrightarrow{L}|$:\n",
    "\n",
    "        ![Calculo de R](15_Iluminacao06.png)\n",
    "    \n",
    "\n",
    "    * **Modelo de Phong simplificado**: utilizando vetor intermediário $\\overrightarrow{H} = \\frac{\\overrightarrow{L} - \\overrightarrow{V}}{|\\overrightarrow{L} - \\overrightarrow{V}|}$. Vide imagem a seguir. Motivação: para superfícies não planares, $\\overrightarrow{N} \\cdot \\overrightarrow{H}$ requer menos cálculos do que $\\overrightarrow{V} \\cdot \\overrightarrow{R}$, uma vez que o cálculo de $\\overrightarrow{R}$ envolve saber a normal da superfície. Outro questão é que, se a posição da visão e da fonte de luz forem distantes, $\\overrightarrow{V}$ e $\\overrightarrow{L}$ serão constantes e $\\overrightarrow{H}$ será constante também. Neste caso, se $\\overrightarrow{N} \\cdot \\overrightarrow{H}$ for usado, tracaremos $cos(\\phi$) por $cos(\\alpha)$.\n",
    "\n",
    "        ![Calculo de H](15_Iluminacao07.png)\n",
    "\n",
    "**Modelo Final: Ambiente + Difusa + Especular**\n",
    "\n",
    "$$ I = I_{diff} + I_{spec} = k_aI_a + k_dI_l(\\overrightarrow{N} \\cdot \\overrightarrow{L}) + k_sI_l(\\overrightarrow{N} \\cdot \\overrightarrow{H})^{n_s}$$\n",
    "\n",
    "Onde, \n",
    "\n",
    "* $k_a$: coeficiente de reflexão ambiente do objeto, com $k_a \\in [0,1]$\n",
    "* $I_a$: intensidade da luz ambiente, com $I_a \\in [0,1]$\n",
    "* $k_d$: coeficiente de reflexão difusa do objeto, com $k_d \\in [0,1]$\n",
    "* $I_l$: intensidade da luz pontual, com $I_l \\in [0,1]$\n",
    "* $\\overrightarrow{N}$: vetor unitário normal à superfície\n",
    "* $\\overrightarrow{L}$: vetor unitário que representa a direção da Luz\n",
    "* $k_s$: coeficiente de reflexão especular, com $k_s \\in [0,1]$\n",
    "* $n_s$: expoente de reflexão especular\n",
    "* $\\overrightarrow{H}$: vetor unitário intermediário entre o vetor unitário que representa a direção da Lu e vetor unitário que representa a direção do observador\n",
    "\n",
    "Observações:\n",
    "\n",
    "* $\\overrightarrow{N} \\cdot \\overrightarrow{L} \\leq 0.0$: objeto será iluminado apenas pela luz ambiente\n",
    "* $\\overrightarrow{N} \\cdot \\overrightarrow{H} \\leq 0.0$: não existirá reflexão especular\n",
    "\n",
    "**Modelo Final: Múltiplas Fontes**\n",
    "\n",
    "$$ I = I_{amb} + \\sum_{l = 1}^{n} [I_{l,diff} + I_{l,spec}] = k_aI_a + \\sum_{l = 1}^{n} I_l[k_d(\\overrightarrow{N} \\cdot \\overrightarrow{L}) + k_s(\\overrightarrow{N} \\cdot \\overrightarrow{H})^{n_s}]$$\n",
    "\n",
    "**Coeficientes de reflexão RGB**\n",
    "\n",
    "Quebrar a iluminação e os coeficientes de reflexão em cores RGB pode facilitar a modelagem do material da superfícies produzindo mais realismo. Desta maneira, teríamos:\n",
    "\n",
    "* $I_l = (I_{lR}, I_{lG}, I_{lB})$\n",
    "* $k_a = (k_{aR}, k_{aG}, k_{aB})$\n",
    "* $k_d = (k_{dR}, k_{dG}, k_{dB})$\n",
    "* $k_s = (k_{sR}, k_{sG}, k_{sB})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bibliotecas\n",
    "try:\n",
    "    import glfw\n",
    "    from OpenGL.GL import *\n",
    "    import numpy as np\n",
    "    import math\n",
    "    import random\n",
    "    import glm\n",
    "    from PIL import Image\n",
    "except ImportError:\n",
    "    !pip install glfw\n",
    "    !pip install pyopengl\n",
    "    !pip install numpy\n",
    "    !pip install pyglm\n",
    "    !pip install pillow\n",
    "    import glfw\n",
    "    from OpenGL.GL import *\n",
    "    import numpy as np\n",
    "    import math\n",
    "    import random\n",
    "    import glm\n",
    "    from PIL import Image\n",
    "\n",
    "#Sistema glfw\n",
    "glfw.init()\n",
    "glfw.window_hint(glfw.VISIBLE, glfw.FALSE)\n",
    "\n",
    "#get_dim_pos: retorna tamanho da tela e posição da tela\n",
    "def get_dim_pos(per_width = 0.6, per_height = 0.6): \n",
    "    # Obtendo configurações do monitor\n",
    "    monitores = glfw.get_monitors()\n",
    "    monitor = monitores[0]\n",
    "    video_mode = glfw.get_video_mode(monitor)\n",
    "    WIDTH_WINDOW, HEIGHT_WINDOW = video_mode.size\n",
    "    # Definindo proporção que se quer do monitor\n",
    "    WIDTH_WINDOW : int = int(per_width*WIDTH_WINDOW)\n",
    "    HEIGHT_WINDOW : int = int(per_height*HEIGHT_WINDOW)\n",
    "    POSX_WINDOW : int = (video_mode.size[0] - WIDTH_WINDOW) // 2\n",
    "    POSY_WINDOW : int = (video_mode.size[1] - HEIGHT_WINDOW) // 2\n",
    "    return WIDTH_WINDOW, HEIGHT_WINDOW, POSX_WINDOW, POSY_WINDOW\n",
    "\n",
    "# Pega tamanho da tela e posição da tela\n",
    "WIDTH_WINDOW, HEIGHT_WINDOW, POSX_WINDOW, POSY_WINDOW = get_dim_pos(0.6,0.6)\n",
    "# Criando janela\n",
    "TITLE: str = \"Iluminação\"\n",
    "window = glfw.create_window(WIDTH_WINDOW, HEIGHT_WINDOW, TITLE, None, None)\n",
    "glfw.set_window_pos(window, POSX_WINDOW, POSY_WINDOW)\n",
    "glfw.make_context_current(window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shaders: Vertex e Fragment\n",
    "\n",
    "Relembrando os três principais tipos de qualificadores do GLSL:\n",
    "* `attribute`: variáveis que representam dados de entrada específicos de cada vértice\n",
    "* `varying`: historicamente dedicado para calcular valores intermediários entre superficies entre primitivas. Porém, com versões recentes, ele também é utilizado para variáveis que são declaradas no shader de vertice e são utilizadas no shader de fragmento. É uma notação alternativa para o conceito de `in` e `out`\n",
    "* `uniform`: variáveis que permanecem constantes durante a execução de um shader\n",
    "\n",
    "**SHADER VERTEX**\n",
    "\n",
    "Relembrando variáveis já utilizadas em outros códigos:\n",
    "* `attribute vec3 position`: coordenadas tridimensionais da posição de um vértice em um espaço 3D\n",
    "* `attribute vec2 texture_coord`: representa as coordenadas de textura 2D associadas ao vértice\n",
    "* `varying vec2 out_texture`: preenchida com as coordenadas de textura associadas a cada vértice, porém de forma interpolada automaticamente entre os vértices ao longo da primitiva durante o processo de renderização\n",
    "* `uniform mat4 model`: matriz model\n",
    "* `uniform mat4 view`: matriz view\n",
    "* `uniform mat4 projection`: matriz projection\n",
    "\n",
    "\n",
    "**Novas variáveis**:\n",
    "* `attribute vec3 normals`: coordenadas tridimensionais da normal de um vértice\n",
    "* `varying vec3 out_fragPos`: posição final do vértice no espaço. Ela é será usado como o vetor $\\overrightarrow{P_{surf}}$ para o cálculo de $\\overrightarrow{L}$ e $\\overrightarrow{V}$ no shader de fragmento no contexto de modelagem de iluminação. Como só queremos a posição e não a renderização final, o valor desta variável é a posição multiplicada pela matriz model. A necessidade dela ser varying porque seu valor será automaticamente passado para o fragment shader, onde poderá ser utilizado conforme necessário\n",
    "* `varying vec3 out_normal`: coordenadas tridimensionais finais da normal do vértice no espaço de mundo. A necessidade dela ser varying porque seu valor será automaticamente passado para o fragment shader, onde poderá ser utilizado conforme necessário\n",
    "\n",
    "\n",
    "**SHADER FRAGMENT**\n",
    "\n",
    "Relembrando variáveis já utilizadas em outros códigos:\n",
    "* `varying vec2 out_texture`: coordenadas com valores interpolados dos vértices de textura vindos do shader de vértice\n",
    "* `uniform sampler2D samplerTexture`: \n",
    "    * `sampler2D`: variável especial em GLSL usado para representar texturas 2D. Ela não armazena a textura de fato, mas possui um identificador para ela\n",
    "    * `samplerTexture`: nome da variável\n",
    "* `vec4 texture = texture2D(samplerTexture, out_texture)`: função usada para amostrar textura 2D. O primeiro argumento é o identificado e a segunda as coordenadas\n",
    "\n",
    "**Novas variáveis Pré-Main**:\n",
    "* `uniform vec3 lightPos`: coordenadas de posição da fonte de luz no espaço 3D. Representa $\\overrightarrow{P_{source}}$ usado para calcular $\\overrightarrow{L}$\n",
    "* `vec3 lightColor = vec3(1.0, 1.0, 1.0)`: cor da luz. Neste caso, branca. Representa $I_a$, $I_l$ e $I_s$\n",
    "* `uniform float ka`: coeficiente de reflexão ambiente $k_a$, que controla a intensidade da iluminação ambiente\n",
    "* `uniform float kd`: coeficiente de reflexão difusa $k_d$, que controla a intensidade da iluminação difusa\n",
    "* `uniform vec3 viewPos`: coordenadas da posição da câmera ou observador no espaço. Representa $\\overrightarrow{P_{cam}}$ usado para calcular $\\overrightarrow{V}$\n",
    "* `uniform float ks`: coeficiente de reflexão especular $k_s$, que controla a intensidade da iluminação especular\n",
    "* `uniform float ns`: expoente de reflexão especular $n_s$, que controla o tamanho do destaque especular\n",
    "* `varying vec3 out_fragPos`: posição final do vértice no espaço. Valores vindos do shader de vértice. Representa vetor $\\overrightarrow{P_{surf}}$ para o cálculo de $\\overrightarrow{L}$ e $\\overrightarrow{V}$\n",
    "* `varying vec3 out_normal`: coordenadas tridimensionais finais da normal do vértice no espaço de mundo. Valores vindos do shader de vértice\n",
    "\n",
    "\n",
    "**Novas variáveis Main**:\n",
    "\n",
    "* REFLEXÃO AMBIENTE:\n",
    "    * `vec3 ambient = ka * lightColor`: representa a parcela $k_aI_a$\n",
    "\n",
    "* REFLEXÃO DIFUSA:\n",
    "    * `vec3 norm = normalize(out_normal)`: transforma $\\overrightarrow{N}$ em unitário\n",
    "    * `vec3 lightDir = normalize(lightPos - out_fragPos)`: calcula $\\overrightarrow{L} = \\frac{\\overrightarrow{P_{source}} - \\overrightarrow{P_{surf}}}{|\\overrightarrow{P_{source}} - \\overrightarrow{P_{surf}}|}$\n",
    "    * `dot(norm, lightDir)`: calcula $\\overrightarrow{N} \\cdot \\overrightarrow{L}$\n",
    "    * `float diff = max(dot(norm, lightDir), 0.0)`: truque para pegar valor $\\overrightarrow{N} \\cdot \\overrightarrow{L}$ apenas no caso em que ele for positivo\n",
    "    * `vec3 diffuse = kd * diff * lightColor`: representa parcela $k_dI_l(\\overrightarrow{N} \\cdot \\overrightarrow{L})$\n",
    "\n",
    "* REFLEXÃO ESPECULAR:\n",
    "    * `vec3 viewDir = normalize(viewPos - out_fragPos)`: calcula $\\overrightarrow{V} = \\frac{\\overrightarrow{P_{cam}} - \\overrightarrow{P_{surf}}}{|\\overrightarrow{P_{cam}} - \\overrightarrow{P_{surf}}|}$\n",
    "    * `vec3 reflectDir = normalize(reflect(-lightDir, norm))`: faz o cálculo de $\\overrightarrow{R}$ automaticamente\n",
    "    * `dot(viewDir, reflectDir)`: calcula $\\overrightarrow{R} \\cdot \\overrightarrow{V}$\n",
    "    * `max(dot(viewDir, reflectDir), 0.0)`: truque para pegar valor $\\overrightarrow{R} \\cdot \\overrightarrow{V}$ apenas no caso em que ele for positivo\n",
    "    * `float spec = pow(max(dot(viewDir, reflectDir), 0.0), ns)`: calcula $(\\overrightarrow{R} \\cdot \\overrightarrow{V})^{n_s}$\n",
    "    * `vec3 specular = ks * spec * lightColor`: representa parcela $k_sI_s(\\overrightarrow{R} \\cdot \\overrightarrow{V})^{n_s}$\n",
    "\n",
    "* MODELO DE PHONG:\n",
    "    * `vec4((ambient + diffuse + specular),1.0)`: representa $k_aI_a + k_dI_d(\\overrightarrow{N} \\cdot \\overrightarrow{L}) + k_sI_s(\\overrightarrow{R} \\cdot \\overrightarrow{V})^{n_s}$\n",
    "    * `vec4 result = vec4((ambient + diffuse + specular),1.0) * texture`: aplicação da iluminação na textura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLSL para Vertex Shader\n",
    "vertex_code = \"\"\"\n",
    "        //POSICAO VERTICES, TEXTURA E NORMAL\n",
    "        attribute vec3 position;\n",
    "        attribute vec2 texture_coord;\n",
    "        attribute vec3 normals;\n",
    "        \n",
    "        //VALORES REPASSADOS PARA O SHADER FRAGMENT\n",
    "        varying vec2 out_texture;\n",
    "        varying vec3 out_fragPos;\n",
    "        varying vec3 out_normal;\n",
    "\n",
    "        //MATRIZES DE TRANSFORMACAO \n",
    "        uniform mat4 model;\n",
    "        uniform mat4 view;\n",
    "        uniform mat4 projection;        \n",
    "        \n",
    "        void main(){\n",
    "            gl_Position = projection * view * model * vec4(position,1.0);\n",
    "            out_texture = vec2(texture_coord);\n",
    "            out_fragPos = vec3(  model * vec4(position, 1.0));\n",
    "            out_normal = vec3( model *vec4(normals, 1.0));            \n",
    "        }\n",
    "        \"\"\"\n",
    "\n",
    "#GLSL para Fragment Shader\n",
    "fragment_code = \"\"\"\n",
    "        // POSICAO DA FONTE DE LUZ E COR DA LUZ\n",
    "        uniform vec3 lightPos; // define coordenadas de posicao da luz\n",
    "        vec3 lightColor = vec3(1.0, 1.0, 1.0);\n",
    "        \n",
    "        // ILUMINACAO AMBIENTE E DIFUSA\n",
    "        uniform float ka; // coeficiente de reflexao ambiente\n",
    "        uniform float kd; // coeficiente de reflexao difusa\n",
    "        \n",
    "        // ILUMINACAO ESPECULAR\n",
    "        uniform vec3 viewPos; // define coordenadas com a posicao da camera/observador\n",
    "        uniform float ks; // coeficiente de reflexao especular\n",
    "        uniform float ns; // expoente de reflexao especular\n",
    "\n",
    "        // VARIAVEIS VINDOS DO SHADER VERTEX\n",
    "        varying vec2 out_texture; // recebido do vertex shader\n",
    "        varying vec3 out_normal; // recebido do vertex shader\n",
    "        varying vec3 out_fragPos; // recebido do vertex shader\n",
    "\n",
    "        // PARAMETRO DE TEXTURA\n",
    "        uniform sampler2D samplerTexture;      \n",
    "        \n",
    "        void main(){\n",
    "            // REFLEXAO AMBIENTE\n",
    "            vec3 ambient = ka * lightColor;             \n",
    "        \n",
    "            // REFLEXAO DIFUSA\n",
    "            vec3 norm = normalize(out_normal); // normaliza vetores perpendiculares\n",
    "            vec3 lightDir = normalize(lightPos - out_fragPos); // direcao da luz\n",
    "            float diff = max(dot(norm, lightDir), 0.0); // verifica limite angular (entre 0 e 90)\n",
    "            vec3 diffuse = kd * diff * lightColor; // iluminacao difusa\n",
    "            \n",
    "            // REFLEXAO ESPECULAR\n",
    "            vec3 viewDir = normalize(viewPos - out_fragPos); // direcao do observador/camera\n",
    "            vec3 reflectDir = normalize(reflect(-lightDir, norm)); // direcao da reflexao\n",
    "            float spec = pow(max(dot(viewDir, reflectDir), 0.0), ns);\n",
    "            vec3 specular = ks * spec * lightColor;             \n",
    "            \n",
    "            // MODELO DE PHONG\n",
    "            vec4 texture = texture2D(samplerTexture, out_texture);\n",
    "            vec4 result = vec4((ambient + diffuse + specular),1.0) * texture; // aplica iluminacao\n",
    "            gl_FragColor = result;\n",
    "        }\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solicitando espaço, compilando e linkando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requisitando slot para GPU\n",
    "program  = glCreateProgram()\n",
    "vertex   = glCreateShader(GL_VERTEX_SHADER)\n",
    "fragment = glCreateShader(GL_FRAGMENT_SHADER)\n",
    "\n",
    "#Associando os códigos aos espaços\n",
    "glShaderSource(vertex, vertex_code)\n",
    "glShaderSource(fragment, fragment_code)\n",
    "\n",
    "#Compilando shader de vértice\n",
    "glCompileShader(vertex)\n",
    "if not glGetShaderiv(vertex, GL_COMPILE_STATUS):\n",
    "    error = glGetShaderInfoLog(vertex).decode()\n",
    "    print(error)\n",
    "    raise RuntimeError(\"Erro de compilacao do Vertex Shader\")\n",
    "\n",
    "#Compilando shader de fragmento\n",
    "glCompileShader(fragment)\n",
    "if not glGetShaderiv(fragment, GL_COMPILE_STATUS):\n",
    "    error = glGetShaderInfoLog(fragment).decode()\n",
    "    print(error)\n",
    "    raise RuntimeError(\"Erro de compilacao do Fragment Shader\")\n",
    "\n",
    "#Associadno programas compilados ao programa principal\n",
    "glAttachShader(program, vertex)\n",
    "glAttachShader(program, fragment)\n",
    "\n",
    "#Linkagem do programa\n",
    "glLinkProgram(program)\n",
    "if not glGetProgramiv(program, GL_LINK_STATUS):\n",
    "    print(glGetProgramInfoLog(program))\n",
    "    raise RuntimeError('Linking error')\n",
    "    \n",
    "#Tornando programa o atual\n",
    "glUseProgram(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função: carrega o arquivo Wavefront\n",
    "# Entrada: nome do arquivo\n",
    "# Saida: estrutura que armazena o elemento (vertices, textura e relations)\n",
    "def load_model_from_file(file_path_name):\n",
    "    # Arrays que armazenaram informações de coordenadas ou vetores\n",
    "    vertices = []       # Posições dos vértices\n",
    "    texture_coords = [] # Coordenada dos vértices de textura\n",
    "    normals = []        # Coordenada que define os vetores normais\n",
    "    relations = []      # Modelo que conecta, a partir da funções dadas no .obj, \n",
    "                        # vértices do objeto, vértices dde textura e os vetores normais\n",
    "\n",
    "    # Não é utilizado, mas refere-se ao material do .obj\n",
    "    material = None\n",
    "\n",
    "    # Abre o arquivo obj (wavefront) para leitura\n",
    "    for line in open(file_path_name, \"r\"): ## para cada linha do arquivo .obj\n",
    "        # Se for comentário, ignore esta linha e use a próxima\n",
    "        if line.startswith('#'): continue\n",
    "\n",
    "        # Quebra a linha por espaço\n",
    "        values = line.split()\n",
    "        # Se não há informações na linha, ignore esta linha e use a próxima\n",
    "        if not values: continue\n",
    "\n",
    "        # Recupera as informações\n",
    "        ### Armazena coordenadas dos vertices do elemento no vetor vertices\n",
    "        if values[0] == 'v':\n",
    "            vertices.append(values[1:4])\n",
    "        ### Armazena vetor normais no vetor normals\n",
    "        elif values[0] == 'vn':\n",
    "            normals.append(values[1:4])\n",
    "        ### Armazena coordenadas das texturas no vetor texture_coords\n",
    "        elif values[0] == 'vt':\n",
    "            texture_coords.append(values[1:3])\n",
    "        ### Define o material \n",
    "        elif values[0] in ('usemtl', 'usemat'):\n",
    "            material = values[1]\n",
    "        ### Armazena informações sobre a construção das relations\n",
    "        elif values[0] == 'f':\n",
    "            # Declara vetores intermediários\n",
    "            relation_vert = []\n",
    "            relation_texture = []\n",
    "            relation_normal = []\n",
    "            # Para cada uma das triplas da linha que define a função\n",
    "            for bloco in values[1:]:\n",
    "                # Separa o elemento em vetor de elementos separando os números que são separados por /\n",
    "                positions = bloco.split('/')\n",
    "                # Adiciona o primeiro número no vetor relation_vert (que representa o número da linha que encontra-se um vértice)\n",
    "                relation_vert.append(int(positions[0]))\n",
    "                # Adiciona o terceiro número no vetor relation_normal (que representa o número da linha que encontra-se a normal para aquele vértice)\n",
    "                relation_normal.append(int(positions[2]))\n",
    "                # Se o vetor com elementos separados por / for maior ou igual que dois\n",
    "                # Se o segundo número do elemento for maior do que zero\n",
    "                if len(positions) >= 2 and len(positions[1]) > 0:\n",
    "                    # Adicione o segundo número no vetor relation_texture (que representa o número da linha que encontra-se um vértice de textura da figura)\n",
    "                    relation_texture.append(int(positions[1]))\n",
    "                else:\n",
    "                    # Se não for maior ou igual a dois ou não for maior que zero, coloque zero na textura\n",
    "                    relation_texture.append(0)\n",
    "            # Após conseguir, provavelmente, os três valores para vértice, os três valores para textura, os três valores para normal e o tipo de material, insira no vetor relations\n",
    "            relations.append((relation_vert, relation_texture, relation_normal, material))\n",
    "\n",
    "    # Armazena cada uma das partes do modelo\n",
    "    model = {}\n",
    "    model['vertices'] = vertices\n",
    "    model['texture'] = texture_coords\n",
    "    model['relations'] = relations\n",
    "    model['normals'] = normals\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função: associa id com a textura\n",
    "#Entradas: o id que queremos associar e o caminho do arquivo .jpg\n",
    "#Saida: não possui, apenas associa\n",
    "def load_texture_from_file(texture_id, img_textura):\n",
    "    #Definindo o id\n",
    "    glBindTexture(GL_TEXTURE_2D, texture_id)\n",
    "    #Alterando configurações paramétricas de textura\n",
    "    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_REPEAT)\n",
    "    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_REPEAT)\n",
    "    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR)\n",
    "    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR)\n",
    "    #Abre imagem\n",
    "    img = Image.open(img_textura)\n",
    "    #Captura as dimensões\n",
    "    img_width = img.size[0]\n",
    "    img_height = img.size[1]\n",
    "    #Transforma imagem para um sequência de bytes em formato raw de arquivo\n",
    "    image_data = img.tobytes(\"raw\", \"RGB\", 0, -1)\n",
    "    #Carregando os dados da imagem\n",
    "    glTexImage2D(GL_TEXTURE_2D, 0, GL_RGB, img_width, img_height, 0, GL_RGB, GL_UNSIGNED_BYTE, image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função: retorna uma lista para coordenadas dos vertices do objeto, outra para as da textura e outra para as das normais\n",
    "def get_vertices_textures_normals(model):\n",
    "    vertices_list = []    \n",
    "    textures_coord_list = []\n",
    "    normals_list = []\n",
    "    # Para cada um das relations (num_line(v), num_line(vt), num_line(vn) material)\n",
    "    for relation in model['relations']:\n",
    "        # Para cada um dos números que representa a linha do vértice\n",
    "        for vertice_id in relation[0]: # Pega o valor a coordenada do vértice\n",
    "            vertices_list.append( model['vertices'][vertice_id-1] )\n",
    "        # Para cada um dos números que representa a linha da coordenada da textura\n",
    "        for texture_id in relation[1]:  # Pega o valor a coordenada da textura\n",
    "            textures_coord_list.append( model['texture'][texture_id-1] )\n",
    "        # Para cada um dos números que representa a linha da coordenada da normal\n",
    "        for normal_id in relation[2]:\n",
    "            normals_list.append( model['normals'][normal_id-1] )\n",
    "    return vertices_list, textures_coord_list, normals_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ativando texturas 2D\n",
    "glEnable(GL_TEXTURE_2D)\n",
    "#Gerando ids\n",
    "num_textures = 10\n",
    "textures = glGenTextures(num_textures)\n",
    "\n",
    "#Carregando modelo\n",
    "PATH_WAVE : str = 'objetos_wavefront'\n",
    "CAIXA_PATH_OBJ : str = f'{PATH_WAVE}\\caixa\\caixa.obj'\n",
    "CAIXA_PATH_JPG : str = f'{PATH_WAVE}\\caixa\\caixa.jpg'\n",
    "modelo = load_model_from_file(CAIXA_PATH_OBJ)\n",
    "#Carregando imagem\n",
    "id_caixa = 0\n",
    "load_texture_from_file(id_caixa, CAIXA_PATH_JPG)\n",
    "#Carregando coordenadas de vertice e textura\n",
    "vertices_list, textures_coord_list, normals_list = get_vertices_textures_normals(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finaliza a modelagem dos dados de vértices\n",
    "vertices = np.zeros(len(vertices_list), [(\"position\", np.float32, 3)])\n",
    "vertices['position'] = vertices_list\n",
    "\n",
    "#Finaliza a modelagem dos dados de texturas\n",
    "textures = np.zeros(len(textures_coord_list), [(\"position\", np.float32, 2)])\n",
    "textures['position'] = textures_coord_list\n",
    "\n",
    "#Finaliza a modelagem dos dados das normais\n",
    "normals = np.zeros(len(normals_list), [(\"position\", np.float32, 3)])\n",
    "normals['position'] = normals_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solicita dois buffers para GPU\n",
    "buffer = glGenBuffers(3)\n",
    "\n",
    "# Enviando dados de vértice\n",
    "#Tornando o buffer o buffer padrão de dados\n",
    "glBindBuffer(GL_ARRAY_BUFFER, buffer[0])\n",
    "#Subindo os dados de vértice para o buffer na GPU\n",
    "glBufferData(GL_ARRAY_BUFFER, vertices.nbytes, vertices, GL_STATIC_DRAW)\n",
    "#Encontrando informações de stride e offset dos vértices\n",
    "stride = vertices.strides[0]\n",
    "offset = ctypes.c_void_p(0)\n",
    "#Capturando posição do atributo \"position\" e habilitando\n",
    "loc_vertices = glGetAttribLocation(program, \"position\")\n",
    "glEnableVertexAttribArray(loc_vertices)\n",
    "#Linkando dados ao atributo \"position\"\n",
    "glVertexAttribPointer(loc_vertices, 3, GL_FLOAT, False, stride, offset)\n",
    "\n",
    "# Enviando dados de textura\n",
    "#Tornando o buffer o buffer padrão de dados\n",
    "glBindBuffer(GL_ARRAY_BUFFER, buffer[1])\n",
    "#Subindo os dados de textura para o buffer na GPU\n",
    "glBufferData(GL_ARRAY_BUFFER, textures.nbytes, textures, GL_STATIC_DRAW)\n",
    "#Encontrando informações de stride e offset das texturas\n",
    "stride = textures.strides[0]\n",
    "offset = ctypes.c_void_p(0)\n",
    "#Capturando posição do atributo \"texture_coord\" e habilitando\n",
    "loc_texture_coord = glGetAttribLocation(program, \"texture_coord\")\n",
    "glEnableVertexAttribArray(loc_texture_coord)\n",
    "#Linkando dados ao atributo \"texture_coord\"\n",
    "glVertexAttribPointer(loc_texture_coord, 2, GL_FLOAT, False, stride, offset)\n",
    "\n",
    "\n",
    "# Enviando dados das normais\n",
    "#Tornando o buffer o buffer padrão de dados\n",
    "glBindBuffer(GL_ARRAY_BUFFER, buffer[2])\n",
    "#Subindo os dados das normais para o buffer na GPU\n",
    "glBufferData(GL_ARRAY_BUFFER, normals.nbytes, normals, GL_STATIC_DRAW)\n",
    "#Encontrando informações de stride e offset das normais\n",
    "stride = normals.strides[0]\n",
    "offset = ctypes.c_void_p(0)\n",
    "#Capturando posição do atributo \"normals\" e habilitando\n",
    "loc_normals_coord = glGetAttribLocation(program, \"normals\")\n",
    "glEnableVertexAttribArray(loc_normals_coord)\n",
    "#Linkando dados ao atributo \"normals\"\n",
    "glVertexAttribPointer(loc_normals_coord, 3, GL_FLOAT, False, stride, offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desenha_caixa():\n",
    "    # aplica a matriz model\n",
    "    angle = 0.0\n",
    "    \n",
    "    r_x = 0.0; r_y = 1.0; r_z = 0.0;\n",
    "    \n",
    "    # translacao\n",
    "    t_x = 0.0; t_y = 0.0; t_z = 0.0;\n",
    "    \n",
    "    # escala\n",
    "    s_x = 1.0; s_y = 1.0; s_z = 1.0;\n",
    "    \n",
    "    mat_model = model(angle, r_x, r_y, r_z, t_x, t_y, t_z, s_x, s_y, s_z)\n",
    "    loc_model = glGetUniformLocation(program, \"model\")\n",
    "    glUniformMatrix4fv(loc_model, 1, GL_TRUE, mat_model)\n",
    "       \n",
    "    \n",
    "    #### define parametros de ilumincao do modelo\n",
    "    ka = 0.1 # coeficiente de reflexao ambiente do modelo\n",
    "    kd = 0.5 # coeficiente de reflexao difusa do modelo\n",
    "    ks = 0.9 # coeficiente de reflexao especular do modelo\n",
    "    ns = ns_inc # expoente de reflexao especular\n",
    "    \n",
    "    loc_ka = glGetUniformLocation(program, \"ka\") # recuperando localizacao da variavel ka na GPU\n",
    "    glUniform1f(loc_ka, ka) ### envia ka pra gpu\n",
    "    \n",
    "    loc_kd = glGetUniformLocation(program, \"kd\") # recuperando localizacao da variavel kd na GPU\n",
    "    glUniform1f(loc_kd, kd) ### envia kd pra gpu    \n",
    "    \n",
    "    loc_ks = glGetUniformLocation(program, \"ks\") # recuperando localizacao da variavel ks na GPU\n",
    "    glUniform1f(loc_ks, ks) ### envia ks pra gpu        \n",
    "    \n",
    "    loc_ns = glGetUniformLocation(program, \"ns\") # recuperando localizacao da variavel ns na GPU\n",
    "    glUniform1f(loc_ns, ns) ### envia ns pra gpu        \n",
    "\n",
    "    \n",
    "    #define id da textura do modelo\n",
    "    glBindTexture(GL_TEXTURE_2D, 0)\n",
    "    \n",
    "    \n",
    "    # desenha o modelo\n",
    "    glDrawArrays(GL_TRIANGLES, 0, 36) ## renderizando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulação dos espaços de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requisitando espaço de buffer para GPU\n",
    "buffer = glGenBuffers(1)\n",
    "#Tornando o buffer o buffer padrão de dados\n",
    "glBindBuffer(GL_ARRAY_BUFFER, buffer)\n",
    "#Subindo os dados de vértice para o buffer na GPU\n",
    "glBufferData(GL_ARRAY_BUFFER, vertices.nbytes, vertices, GL_DYNAMIC_DRAW)\n",
    "#glBindBuffer(GL_ARRAY_BUFFER, buffer)\n",
    "\n",
    "#Encontrando informações de stride e offset dos vértices\n",
    "stride = vertices.strides[0]\n",
    "offset = ctypes.c_void_p(0)\n",
    "#Capturando posição do atributo \"position\" e habilitando. Também captura a posicao de loc_color e loc_mat\n",
    "loc_position = glGetAttribLocation(program, \"position\")\n",
    "loc_color = glGetUniformLocation(program, \"color\")\n",
    "loc_mat = glGetUniformLocation(program, \"mat_transformation\")\n",
    "glEnableVertexAttribArray(loc_position)\n",
    "#Linkando dados ao atributo \"position\"\n",
    "glVertexAttribPointer(loc_position, 3, GL_FLOAT, False, stride, offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eventos para modificar a posição da câmera\n",
    "\n",
    "Aqui será necessário definir três importantes vetores.\n",
    "1. Posição da câmera (`cameraPos`): indica a posição da câmera no cenário. Nesse caso, iniciaremos na coordenada `(0.0, 0.0, 1.0)`\n",
    "2. Frente da câmera (`cameraFront`): direção para a qual a câmera está apontando. Iniciaremos apontando para o centro. Fazemos isso com `(0.0,  0.0, -1.0)`\n",
    "3. Subida da câmera (`cameraUp`): direção do \"para cima\" da câmera. Neste caso, naturalmente é `(0.0,  1.0,  0.0)`.\n",
    "\n",
    "É importante que todos os vetores, inclusive os resultantes das operações entre estes três, tenham módulo unitário. Desta maneira, conseguimos controlar a velocidade da mudança da posição através de uma variável defina apenas para isso: `cameraSpeed`. O módulo 1 pode ser tratado imediatamente antes da geração da matriz final.\n",
    "\n",
    "**Movimentação para frente ou para trás:**\n",
    "\n",
    "Para a câmera se mover para frente, basta que a posição da câmera ande na direção da frente de câmera. Podemos controlar a velocidade disso atráves da variável velocidade. Um ponto importante é caso a câmera esteja apontando para um outro lugar (na diagonal, por exemplo). Neste caso, como a direção está sendo controlado pelos eventos de cursor, a própria função cursor se resopnsabiliza de alterar o vetor `cameraFront` para garantir que ele fique sempre na mesma direção para onde a câmera aponta. Para andar para trás, basta fazer a operação de subtração.\n",
    "\n",
    "**Movimentação para esquerda e direita:**\n",
    "\n",
    "Para a câmera se mover para direita, basta que ande para a direção do produto vetorial entre a direção da frente e a da subida (que gerará um vetor para direita). O único ponto é que o vetor resultante deve ter módulo unitário. Para andar para esquerda, basta subtrair a posição deste vetor ao invés de somar. O módulo 1 pode ser tratado imediatamente antes da geração da matriz final.\n",
    "\n",
    "**Evento de mouse**:\n",
    "\n",
    "Para construir e entender a função evento de mouse, é preciso saber:\n",
    "* Yaw: rotação em torno do eixo y. Define o \"virar a câmera para direita ou esquerda\"\n",
    "* Pitch: rotação em torno do eixo x. Define o \"virar a câmera para cima ou baixo\"\n",
    "\n",
    "Na função, calcula-se a variação de posição do mouse no eixo y e x para definir o yaw e o pitch respectivamente. Considerando apenas uma pequena parcela do valor (cerca de trinta porcento) da variação, podemos assumir, com certo erro, que yaw e pitch sejam de fato a rotação, em graus, da câmera. Com isso, podemos calcular a nova posição da frente de câmera utilizando algumas fórmuals matemáticas (que não é o foco)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posicao inicial da camera\n",
    "cameraPos   = glm.vec3(0.0,  0.0,  1.0)\n",
    "# Vetor responsável para apontar para frente\n",
    "cameraFront = glm.vec3(0.0,  0.0, -1.0)\n",
    "# Vetor auxiliar que aponta para cima em relação a camera\n",
    "cameraUp    = glm.vec3(0.0,  1.0,  0.0)\n",
    "\n",
    "# Funcao que captura evento do teclado\n",
    "def key_event(window,key,scancode,action,mods):\n",
    "    global cameraPos, cameraFront, cameraUp\n",
    "    \n",
    "    # Componentes da câmera\n",
    "    # Velocidade da camera\n",
    "    cameraSpeed = 0.01\n",
    "    # Ir para frente\n",
    "    if key == 87 and (action==1 or action==2): # Tecla W\n",
    "        cameraPos += cameraSpeed * cameraFront\n",
    "    # Ir para trás\n",
    "    if key == 83 and (action==1 or action==2): # Tecla S\n",
    "        cameraPos -= cameraSpeed * cameraFront\n",
    "    # Ir para esquerda\n",
    "    if key == 65 and (action==1 or action==2): # Tecla A\n",
    "        cameraPos -= glm.normalize(glm.cross(cameraFront, cameraUp)) * cameraSpeed\n",
    "    # Ir para direita    \n",
    "    if key == 68 and (action==1 or action==2): # Tecla D\n",
    "        cameraPos += glm.normalize(glm.cross(cameraFront, cameraUp)) * cameraSpeed\n",
    "\n",
    "# Variáveis auxiliar\n",
    "# Flag para definir se eh a primeira vez que o mouse aparece na tela\n",
    "firstMouse = True\n",
    "# yaw: rotação no eixo y\n",
    "yaw = -90.0 \n",
    "# pitch: rotação no eixo x\n",
    "pitch = 0.0\n",
    "# Valores iniciais da última posição do mouse\n",
    "lastX =  WIDTH_WINDOW/2\n",
    "lastY =  HEIGHT_WINDOW/2\n",
    "\n",
    "def mouse_event(window, xpos, ypos):\n",
    "    global firstMouse, cameraFront, yaw, pitch, lastX, lastY\n",
    "    # Tratando caso de primeira aparição do mouse\n",
    "    if firstMouse:\n",
    "        lastX = xpos\n",
    "        lastY = ypos\n",
    "        firstMouse = False\n",
    "\n",
    "    # Calculos da variação\n",
    "    xoffset = xpos - lastX\n",
    "    yoffset = lastY - ypos\n",
    "    # Atualizando valor da última posição\n",
    "    lastX = xpos\n",
    "    lastY = ypos\n",
    "    # Calculando yam e pitch aproximadamente\n",
    "    sensitivity = 0.3 \n",
    "    xoffset *= sensitivity\n",
    "    yoffset *= sensitivity\n",
    "    yaw += xoffset\n",
    "    pitch += yoffset\n",
    "\n",
    "    # Evitando que rotação extremas\n",
    "    if pitch >= 90.0: pitch = 90.0\n",
    "    if pitch <= -90.0: pitch = -90.0\n",
    "\n",
    "    # Fórmulas matemáticas para calcular o novo cameraFront\n",
    "    front = glm.vec3()\n",
    "    front.x = math.cos(glm.radians(yaw)) * math.cos(glm.radians(pitch))\n",
    "    front.y = math.sin(glm.radians(pitch))\n",
    "    front.z = math.sin(glm.radians(yaw)) * math.cos(glm.radians(pitch))\n",
    "    cameraFront = glm.normalize(front)\n",
    "\n",
    "# Define função de evento para teclado\n",
    "glfw.set_key_callback(window,key_event)\n",
    "# Define função de evento para cursor\n",
    "glfw.set_cursor_pos_callback(window, mouse_event)\n",
    "# Seta posição do cursor\n",
    "# glfw.set_cursor_pos(window, lastX, lastY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo matrizes model, view e projection\n",
    "\n",
    "**Mariz View**\n",
    "\n",
    "Considerando que o vetor normal $\\overrightarrow{N}$ é o vetor que parte do \"target\" e até a posição da câmera dado por $P_0 = (x_0, y_0, z_0)$, temos que:\n",
    "* Câmera frente: $\\overrightarrow{n} = \\frac{\\overrightarrow{N}}{|\\overrightarrow{N}|} = (n_x,n_y,n_z)$\n",
    "* Câmera subida intermediária:  $\\overrightarrow{V}$ (geralmente dado como $(0.0,1.0,0.0)$)\n",
    "* Câmera direita: $\\overrightarrow{u} = \\frac{\\overrightarrow{V} \\times \\overrightarrow{n}}{|\\overrightarrow{V} \\times \\overrightarrow{n}|} = (u_x,u_y,u_z)$\n",
    "* Câmera subida: $\\overrightarrow{v} = \\overrightarrow{n} \\times \\overrightarrow{u} = (v_x, v_y, v_z)$ \n",
    "Por fim, a matriz view é: \n",
    "$View = \\begin{bmatrix}\n",
    "u_x & u_y & u_z & -u \\cdot P_0\\\\ \n",
    "v_x & v_y & v_z & -v \\cdot P_0\\\\  \n",
    "n_x & n_y & n_z & -n \\cdot P_0\\\\ \n",
    "0 & 0 & 0 & 1 \n",
    "\\end{bmatrix}$\n",
    "\n",
    "**Mariz Projection**\n",
    "\n",
    "Para construir, é importante destacar alguns termos desta imagem: \n",
    "\n",
    "![Termos da Projecao](14_Camera.png)\n",
    "* Field of View (FOV): ângulo de visão da câmera\n",
    "* Clipping window (Janela de Recorte): retângulo sobre o qual os objetos serão projetados\n",
    "* Eixo $z_{view}$: é o eixo definido pelo vetor câmera frente\n",
    "* Far Clipping Plane: plano imaginário que está localizado longe da câmera. Objetos que estão mais longes do que este plano não serão renderizados. Perpendicular ao eixo $z_{view}$.\n",
    "* Near Clipping Plane: plano imaginário que está localizado perto da câmera. Objetos que estão mais próximos do que este plano não serão renderizados. Perpendicular ao eixo $z_{view}$.\n",
    "* Frustum View Volume: tronco-piramidal que resulta da seção da pirâmide pelos planos paralelos Far e Near. Descreve o que será visível pela câmera.\n",
    "\n",
    "Descrito isso, define-se:\n",
    "* $\\theta$: FOV\n",
    "* $z_{near}$: distância da câmera até o plano de visão mais perto\n",
    "* $z_{far}$: distância da câmera até o plano de visão mais distante\n",
    "* $width$: largura da Clipping Window\n",
    "* $height$: altura da Clipping Window\n",
    "* $aspect$: relação $width/height$\n",
    "\n",
    "Assim, a matriz projection é:\n",
    "$Projection = \\begin{bmatrix}\n",
    "\\frac{cot(\\frac{\\theta}{2})}{aspect} & 0 & 0 & 0\\\\ \n",
    "0 & cot(\\theta/2) & 0z & 0\\\\  \n",
    "0 & 0 & \\frac{z_{near} + z_{far}}{z_{near} - z_{far}} & - \\frac{2\\cdot z_{near}\\cdot z_{far}}{z_{near} - z_{far}} \\\\ \n",
    "0 & 0 & -1 & 0 \n",
    "\\end{bmatrix}$\n",
    "\n",
    "Link para entender melhor o impacto de cada variável: https://webglfundamentals.org/webgl/frustum-diagram.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz model: posição, orientação e escala do objeto no próprio espaço local\n",
    "def model():\n",
    "    # Neste exemplo, a matriz model não altera nenhum objeto\n",
    "    mat_model = glm.mat4(1.0) # Matriz identidade\n",
    "    mat_model = np.array(mat_model)    \n",
    "    return mat_model\n",
    "\n",
    "# Matriz view: posição e orientação da câmera no espaço 3D. Posiciona a cena em relação à câmera.\n",
    "def view():\n",
    "    global cameraPos, cameraFront, cameraUp\n",
    "    # Parãmetros: posição da câmera, direção do target e câmera up. Câmera direita é calculado internamente pela função da biblioteca glm\n",
    "    mat_view = glm.lookAt(cameraPos, cameraPos + cameraFront, cameraUp)\n",
    "    mat_view = np.array(mat_view)\n",
    "    return mat_view\n",
    "\n",
    "# Matriz Projection: transforma o volume de visualização 3D em um espaço 2D, levando em consideração fatores como a distância dos objetos à câmera\n",
    "def projection():\n",
    "    # Neste caso, definimos parâmetros estáticos, mas poderiam ser dinâmicos\n",
    "    fov = glm.radians(45.0)\n",
    "    aspect = WIDTH_WINDOW/HEIGHT_WINDOW\n",
    "    near = 0.1\n",
    "    far = 100.0\n",
    "    mat_projection = glm.perspective(fov, aspect, near, far)\n",
    "    mat_projection = np.array(mat_projection)    \n",
    "    return mat_projection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando funções de impressão de objetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Habilita 3D\n",
    "glEnable(GL_DEPTH_TEST)\n",
    "\n",
    "def desenha_cubo1():\n",
    "    # DESENHANDO O CUBO 1 (vértices de 0 até 23)\n",
    "    for i in range(0,24,4): # incremento de 4 em 4\n",
    "        R = (i+1)/24\n",
    "        G = (i+2)/24\n",
    "        B = (i+3)/24\n",
    "        glUniform4f(loc_color, R, G, B, 1.0) ### definindo uma cor qualquer com base no i\n",
    "        glDrawArrays(GL_TRIANGLE_STRIP, i, 4)\n",
    "    \n",
    "def desenha_cubo2():\n",
    "    # DESENHANDO O CUBO 2 (vértices de 24 até 47)\n",
    "    for i in range(24,48,4): # incremento de 4 em 4\n",
    "        R = (i+1)/48\n",
    "        G = (i+2)/48\n",
    "        B = (i+3)/48\n",
    "        glUniform4f(loc_color, R, G, B, 1.0) ### definindo uma cor qualquer com base no i\n",
    "        glDrawArrays(GL_TRIANGLE_STRIP, i, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exibindo na tela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "glfw.show_window(window)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop principal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not glfw.window_should_close(window):\n",
    "    glfw.poll_events() \n",
    "    glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT)\n",
    "    glClearColor(1.0, 1.0, 1.0, 1.0)\n",
    "\n",
    "    # Computando e enviando matrizes Model, View e Projection para a GPU\n",
    "    mat_model = model()\n",
    "    loc_model = glGetUniformLocation(program, \"model\")\n",
    "    glUniformMatrix4fv(loc_model, 1, GL_TRUE, mat_model)\n",
    "    \n",
    "    mat_view = view()\n",
    "    loc_view = glGetUniformLocation(program, \"view\")\n",
    "    glUniformMatrix4fv(loc_view, 1, GL_TRUE, mat_view)\n",
    "\n",
    "    mat_projection = projection()\n",
    "    loc_projection = glGetUniformLocation(program, \"projection\")\n",
    "    glUniformMatrix4fv(loc_projection, 1, GL_TRUE, mat_projection)    \n",
    "    \n",
    "    # Desenhando objetos\n",
    "    desenha_cubo1()\n",
    "    desenha_cubo2()\n",
    "\n",
    "    glfw.swap_buffers(window)\n",
    "\n",
    "glfw.terminate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
